{"version":3,"sources":["../src/lexicalAnalysis.js"],"names":["maps","fs","require","DOCUMENT_PATH","BUFFER_LENGTH","identifier","results","console","log","open","err","fd","error","lexicalAnalysis","close","showResult","file","buffer","BufferStorage","start","end","state","isSearching","charter","getCharacter","nextIndex","match","BASE","OFFSET_MAP","get","CHECK","isFileEnd","NEXT","token","getString","result","type","value","push","STATE_MAP","parseInt","DEFAULT","forEach"],"mappings":";;AAaA;;;;AACA;;IAAYA,I;;;;;;AAAoB;AAdhC;;;;;;;;;AAUA;;;AAKA,IAAIC,KAAKC,QAAQ,IAAR,CAAT,C,CAAwB;;;AAGxB;;;AAL6C;AAQ7C,IAAMC,gBAAgB,qBAAtB;AAAA,IAA6C;AAC3CC,gBAAgB,EADlB,C,CACsB;;;AAGtB;;;AAGA,IAAIC,aAAa,EAAjB;AAAA,IAAqB;AACnBC,UAAU,EADZ,C,CACgB;;;AAGhB;;;AAGAC,QAAQC,GAAR,CAAY,gBAAgBL,aAA5B;AACAF,GAAGQ,IAAH,CAAQN,aAAR,EAAuB,IAAvB,EAA6B,UAAUO,GAAV,EAAeC,EAAf,EAAmB;;AAE9C;AACA,MAAID,GAAJ,EAAS;AACP,WAAOH,QAAQK,KAAR,CAAcF,GAAd,CAAP;AACD;;AAEDH,UAAQC,GAAR,CAAY,SAAZ;AACAD,UAAQC,GAAR,CAAY,eAAZ;AACAK,kBAAgBF,EAAhB;;AAEA;AACAV,KAAGa,KAAH,CAASH,EAAT,EAAa,UAAUD,GAAV,EAAe;AAC1B,QAAIA,GAAJ,EAAS;AACPH,cAAQC,GAAR,CAAYE,GAAZ;AACD;AACDH,YAAQC,GAAR,CAAY,WAAZ;AACAO,eAAWT,OAAX;AACD,GAND;AAOD,CAnBD;;AAsBA;;;;AAIA,SAASO,eAAT,GAAsC;AAAA,MAAbG,IAAa,uEAAN,IAAM;;AACpC,MAAIC,SAAS,IAAIC,uBAAJ,CAAkBF,IAAlB,EAAwBZ,aAAxB,CAAb;AAAA,MAAqD;AACnDe,UAAQ,CADV;AAAA,MACa;AACXC,QAAM,CAFR;AAAA,MAEW;AACTC,UAAQ,CAHV;AAAA,MAGa;AACXC,gBAAc,IAJhB,CADoC,CAKd;;AAEtB,KAAG;AACD,QAAI,CAACA,WAAL,EAAkB;AAChBF;AACAE,oBAAc,IAAd;AACD;AACD,QAAIC,UAAUN,OAAOO,YAAP,CAAoBJ,GAApB,CAAd;AAAA,QACEK,YAAY,CADd;;AAGA;AACA,QAAIF,QAAQG,KAAR,CAAc,UAAd,CAAJ,EAA+B;AAC7BD,kBAAYzB,KAAK2B,IAAL,CAAUN,KAAV,IAAmBrB,KAAK4B,UAAL,CAAgBC,GAAhB,CAAoB,OAApB,CAA/B;AACD,KAFD,MAEO,IAAIN,QAAQG,KAAR,CAAc,aAAd,CAAJ,EAAkC;AACvCD,kBAAYzB,KAAK2B,IAAL,CAAUN,KAAV,IAAmBrB,KAAK4B,UAAL,CAAgBC,GAAhB,CAAoB,QAApB,CAA/B;AACD,KAFM,MAEA,IAAIN,QAAQG,KAAR,CAAc,QAAd,KAA2BH,QAAQG,KAAR,CAAc,QAAd,CAA/B,EAAwD;AAC7DD,kBAAYzB,KAAK2B,IAAL,CAAUN,KAAV,IAAmBrB,KAAK4B,UAAL,CAAgBC,GAAhB,CAAoB,OAApB,CAA/B;AACD,KAFM,MAEA;AACLJ,kBAAYzB,KAAK2B,IAAL,CAAUN,KAAV,IAAmBrB,KAAK4B,UAAL,CAAgBC,GAAhB,CAAoBN,OAApB,CAA/B;AACD;;AAED;AACA,QAAIvB,KAAK8B,KAAL,CAAWL,SAAX,MAA0B,EAA1B,IAAgCzB,KAAK8B,KAAL,CAAWL,SAAX,MAA0BJ,KAA1D,IAAmE,CAACJ,OAAOc,SAAP,CAAiBX,MAAM,CAAvB,CAAxE,EAAmG;AACjGC,cAAQrB,KAAKgC,IAAL,CAAUP,SAAV,CAAR;AACA;AACD,KAHD,MAGO;AAAE;AACP,UAAIQ,QAAQhB,OAAOiB,SAAP,CAAiBf,KAAjB,EAAwBC,GAAxB,CAAZ;AAAA,UACEe,SAAS;AACPC,cAAM,EADC;AAEPC,eAAO;AAFA,OADX;;AAMA,cAAQhB,KAAR;AACE,aAAK,CAAL;AAAQ;AACNhB,qBAAWiC,IAAX,CAAgBL,KAAhB;AACA,cAAIjC,KAAKuC,SAAL,CAAeV,GAAf,CAAmBI,KAAnB,CAAJ,EAA+B;AAC7BE,mBAAOC,IAAP,GAAcpC,KAAKuC,SAAL,CAAeV,GAAf,CAAmBI,KAAnB,CAAd;AACAE,mBAAOE,KAAP,GAAeJ,KAAf;AACD,WAHD,MAGO;AACLE,mBAAOC,IAAP,GAAcpC,KAAKuC,SAAL,CAAeV,GAAf,CAAmB,YAAnB,CAAd;AACAM,mBAAOE,KAAP,GAAeJ,KAAf;AACD;AACD;AACF,aAAK,CAAL;AAAQ;AACNE,iBAAOC,IAAP,GAAcpC,KAAKuC,SAAL,CAAeV,GAAf,CAAmB,KAAnB,CAAd;AACAM,iBAAOE,KAAP,GAAeG,SAASP,KAAT,CAAf;AACA;AACF,aAAK,EAAL;AAAS;AACP;AACF;AACE,cAAIjC,KAAKuC,SAAL,CAAeV,GAAf,CAAmBI,KAAnB,CAAJ,EAA+B;AAC7BE,mBAAOC,IAAP,GAAcpC,KAAKuC,SAAL,CAAeV,GAAf,CAAmBI,KAAnB,CAAd;AACAE,mBAAOE,KAAP,GAAeJ,KAAf;AACD;AArBL;;AAwBA,UAAIE,OAAOC,IAAX,EAAiB;AACf9B,gBAAQgC,IAAR,CAAaH,MAAb;AACD;;AAEDd,cAAQrB,KAAKyC,OAAL,CAAapB,KAAb,CAAR;AACAF,cAAQC,GAAR;AACAE,oBAAc,KAAd;AACD;AAEF,GA/DD,QA+DS,CAACL,OAAOc,SAAP,CAAiB,EAAEX,GAAnB,CA/DV;AAiED;;AAID;;;;AAIA,SAASL,UAAT,GAAkC;AAAA,MAAdT,OAAc,uEAAJ,EAAI;;AAChCA,UAAQoC,OAAR,CAAgB,iBAAS;AACvBnC,YAAQC,GAAR,CAAY,MAAMyB,MAAMG,IAAZ,GAAmB,GAAnB,GAAyBH,MAAMI,KAA/B,GAAuC,GAAnD;AACD,GAFD;AAGD","file":"lexicalAnalysis.js","sourcesContent":["/*\r\n * @Author: zhouyou@werun \r\n * @Descriptions: js 实现 c 语言的词法分析器\r\n * @TodoList: 无\r\n * @Date: 2018-10-20 18:46:33 \r\n * @Last Modified by: zhouyou@werun\r\n * @Last Modified time: 2018-10-25 11:09:49\r\n */\r\n\r\n\r\n/**\r\n * 依赖模块引入\r\n */\r\nimport BufferStorage from './BufferStorage'; // 引入 BufferStorage 缓存区操作类\r\nimport * as maps from './maps'; // 引入字符偏移量映射表\r\nlet fs = require(\"fs\"); // 引入文件模块依赖\r\n\r\n\r\n/**\r\n * 常量定义\r\n */\r\nconst DOCUMENT_PATH = \"./document/test.txt\", // 源文件路径\r\n  BUFFER_LENGTH = 10; // 缓存区长度\r\n\r\n\r\n/**\r\n * 全局变量定义\r\n */\r\nlet identifier = [], // 标识符识别表\r\n  results = []; // 存放结果数组\r\n\r\n\r\n/**\r\n * 打开并处理文件\r\n */\r\nconsole.log(\"准备打开已存在的文件：\" + DOCUMENT_PATH);\r\nfs.open(DOCUMENT_PATH, 'r+', function (err, fd) {\r\n\r\n  // 错误处理\r\n  if (err) {\r\n    return console.error(err);\r\n  }\r\n\r\n  console.log(\"文件打开成功！\");\r\n  console.log(\"开始对源文件进行词法分析！\");\r\n  lexicalAnalysis(fd);\r\n\r\n  // 关闭文件\r\n  fs.close(fd, function (err) {\r\n    if (err) {\r\n      console.log(err);\r\n    }\r\n    console.log(\"词法分析结果如下：\");\r\n    showResult(results);\r\n  });\r\n});\r\n\r\n\r\n/**\r\n * @description 词法分析操作函数\r\n * @param {*} [file=null] 文件标识符\r\n */\r\nfunction lexicalAnalysis(file = null) {\r\n  let buffer = new BufferStorage(file, BUFFER_LENGTH), // 缓存区\r\n    start = 0, // 字符串状态的开始索引\r\n    end = 0, // 字符串状态的结束索引\r\n    state = 0, // 状态机状态\r\n    isSearching = true; // 判断是否处于状态转移的过程中\r\n\r\n  do {\r\n    if (!isSearching) {\r\n      end--;\r\n      isSearching = true;\r\n    }\r\n    let charter = buffer.getCharacter(end),\r\n      nextIndex = 0;\r\n\r\n    // 获取 next 映射表中的索引值\r\n    if (charter.match(/^[0-9]*$/)) {\r\n      nextIndex = maps.BASE[state] + maps.OFFSET_MAP.get(\"digit\");\r\n    } else if (charter.match(/^[A-Za-z]+$/)) {\r\n      nextIndex = maps.BASE[state] + maps.OFFSET_MAP.get(\"letter\");\r\n    } else if (charter.match(/^[ ]+$/) || charter.match(/[\\r\\n]/)) {\r\n      nextIndex = maps.BASE[state] + maps.OFFSET_MAP.get(\"space\");\r\n    } else {\r\n      nextIndex = maps.BASE[state] + maps.OFFSET_MAP.get(charter);\r\n    }\r\n\r\n    // 状态转移判断\r\n    if (maps.CHECK[nextIndex] !== \"\" && maps.CHECK[nextIndex] === state && !buffer.isFileEnd(end + 1)) {\r\n      state = maps.NEXT[nextIndex];\r\n      continue;\r\n    } else { // 对应不同状态，截取字符串进行判断\r\n      let token = buffer.getString(start, end),\r\n        result = {\r\n          type: \"\",\r\n          value: \"\",\r\n        }\r\n\r\n      switch (state) {\r\n        case 1: // 处理标识符的情况\r\n          identifier.push(token);\r\n          if (maps.STATE_MAP.get(token)) {\r\n            result.type = maps.STATE_MAP.get(token);\r\n            result.value = token;\r\n          } else {\r\n            result.type = maps.STATE_MAP.get(\"identifier\");\r\n            result.value = token;\r\n          }\r\n          break;\r\n        case 2: // 处理整数的情况\r\n          result.type = maps.STATE_MAP.get(\"int\");\r\n          result.value = parseInt(token);\r\n          break;\r\n        case 18: // 处理空字符的情况\r\n          break;\r\n        default:\r\n          if (maps.STATE_MAP.get(token)) {\r\n            result.type = maps.STATE_MAP.get(token);\r\n            result.value = token;\r\n          }\r\n      }\r\n\r\n      if (result.type) {\r\n        results.push(result);\r\n      }\r\n\r\n      state = maps.DEFAULT[state];\r\n      start = end;\r\n      isSearching = false;\r\n    }\r\n\r\n  } while (!buffer.isFileEnd(++end));\r\n\r\n}\r\n\r\n\r\n\r\n/**\r\n * @description 显示词法分析结果\r\n * @param {*} [results=[]] 结果数组\r\n */\r\nfunction showResult(results = []) {\r\n  results.forEach(token => {\r\n    console.log(\"(\" + token.type + \",\" + token.value + \")\")\r\n  });\r\n}"]}